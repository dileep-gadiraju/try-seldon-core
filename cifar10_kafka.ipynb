{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seldon Kafka Integration Example with CIFAR10 Model\n",
    "\n",
    "In this example we will run SeldonDeployments for a CIFAR10 Tensorflow model which take their inputs from a Kafka topic and push their outputs to a Kafka topic. We will experiment with both REST and gRPC Seldon graphs. For REST we will load our input topic with Tensorflow JSON requests and for gRPC we will load Tensorflow PredictRequest protoBuffers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements\n",
    "\n",
    " * [Install gsutil](https://cloud.google.com/storage/docs/gsutil_install)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gsutil in /Users/dileep.gadiraju/opt/anaconda3/lib/python3.9/site-packages (5.16)\n",
      "Requirement already satisfied: httplib2>=0.20.4 in /Users/dileep.gadiraju/opt/anaconda3/lib/python3.9/site-packages (from gsutil) (0.21.0)\n",
      "Requirement already satisfied: monotonic>=1.4 in /Users/dileep.gadiraju/opt/anaconda3/lib/python3.9/site-packages (from gsutil) (1.6)\n",
      "Requirement already satisfied: google-reauth>=0.1.0 in /Users/dileep.gadiraju/opt/anaconda3/lib/python3.9/site-packages (from gsutil) (0.1.1)\n",
      "Requirement already satisfied: retry-decorator>=1.0.0 in /Users/dileep.gadiraju/opt/anaconda3/lib/python3.9/site-packages (from gsutil) (1.1.1)\n",
      "Requirement already satisfied: pyOpenSSL>=0.13 in /Users/dileep.gadiraju/opt/anaconda3/lib/python3.9/site-packages (from gsutil) (21.0.0)\n",
      "Requirement already satisfied: fasteners>=0.14.1 in /Users/dileep.gadiraju/opt/anaconda3/lib/python3.9/site-packages (from gsutil) (0.18)\n",
      "Requirement already satisfied: argcomplete>=1.9.4 in /Users/dileep.gadiraju/opt/anaconda3/lib/python3.9/site-packages (from gsutil) (2.0.0)\n",
      "Requirement already satisfied: gcs-oauth2-boto-plugin>=3.0 in /Users/dileep.gadiraju/opt/anaconda3/lib/python3.9/site-packages (from gsutil) (3.0)\n",
      "Requirement already satisfied: google-apitools>=0.5.32 in /Users/dileep.gadiraju/opt/anaconda3/lib/python3.9/site-packages (from gsutil) (0.5.32)\n",
      "Requirement already satisfied: google-auth[aiohttp]>=2.5.0 in /Users/dileep.gadiraju/opt/anaconda3/lib/python3.9/site-packages (from gsutil) (2.11.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/dileep.gadiraju/opt/anaconda3/lib/python3.9/site-packages (from gsutil) (1.16.0)\n",
      "Requirement already satisfied: crcmod>=1.7 in /Users/dileep.gadiraju/opt/anaconda3/lib/python3.9/site-packages (from gsutil) (1.7)\n",
      "Requirement already satisfied: oauth2client>=2.2.0 in /Users/dileep.gadiraju/opt/anaconda3/lib/python3.9/site-packages (from gcs-oauth2-boto-plugin>=3.0->gsutil) (4.1.3)\n",
      "Requirement already satisfied: boto>=2.29.1 in /Users/dileep.gadiraju/opt/anaconda3/lib/python3.9/site-packages (from gcs-oauth2-boto-plugin>=3.0->gsutil) (2.49.0)\n",
      "Requirement already satisfied: rsa==4.7.2 in /Users/dileep.gadiraju/opt/anaconda3/lib/python3.9/site-packages (from gcs-oauth2-boto-plugin>=3.0->gsutil) (4.7.2)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /Users/dileep.gadiraju/opt/anaconda3/lib/python3.9/site-packages (from rsa==4.7.2->gcs-oauth2-boto-plugin>=3.0->gsutil) (0.4.8)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/dileep.gadiraju/opt/anaconda3/lib/python3.9/site-packages (from google-auth[aiohttp]>=2.5.0->gsutil) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/dileep.gadiraju/opt/anaconda3/lib/python3.9/site-packages (from google-auth[aiohttp]>=2.5.0->gsutil) (4.2.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0dev,>=3.6.2 in /Users/dileep.gadiraju/opt/anaconda3/lib/python3.9/site-packages (from google-auth[aiohttp]>=2.5.0->gsutil) (3.8.1)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.20.0 in /Users/dileep.gadiraju/opt/anaconda3/lib/python3.9/site-packages (from google-auth[aiohttp]>=2.5.0->gsutil) (2.27.1)\n",
      "Requirement already satisfied: pyu2f in /Users/dileep.gadiraju/opt/anaconda3/lib/python3.9/site-packages (from google-reauth>=0.1.0->gsutil) (0.1.5)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /Users/dileep.gadiraju/opt/anaconda3/lib/python3.9/site-packages (from httplib2>=0.20.4->gsutil) (3.0.4)\n",
      "Requirement already satisfied: cryptography>=3.3 in /Users/dileep.gadiraju/opt/anaconda3/lib/python3.9/site-packages (from pyOpenSSL>=0.13->gsutil) (3.4.8)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/dileep.gadiraju/opt/anaconda3/lib/python3.9/site-packages (from aiohttp<4.0.0dev,>=3.6.2->google-auth[aiohttp]>=2.5.0->gsutil) (4.0.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/dileep.gadiraju/opt/anaconda3/lib/python3.9/site-packages (from aiohttp<4.0.0dev,>=3.6.2->google-auth[aiohttp]>=2.5.0->gsutil) (1.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/dileep.gadiraju/opt/anaconda3/lib/python3.9/site-packages (from aiohttp<4.0.0dev,>=3.6.2->google-auth[aiohttp]>=2.5.0->gsutil) (5.2.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/dileep.gadiraju/opt/anaconda3/lib/python3.9/site-packages (from aiohttp<4.0.0dev,>=3.6.2->google-auth[aiohttp]>=2.5.0->gsutil) (1.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/dileep.gadiraju/opt/anaconda3/lib/python3.9/site-packages (from aiohttp<4.0.0dev,>=3.6.2->google-auth[aiohttp]>=2.5.0->gsutil) (1.6.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/dileep.gadiraju/opt/anaconda3/lib/python3.9/site-packages (from aiohttp<4.0.0dev,>=3.6.2->google-auth[aiohttp]>=2.5.0->gsutil) (21.4.0)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /Users/dileep.gadiraju/opt/anaconda3/lib/python3.9/site-packages (from aiohttp<4.0.0dev,>=3.6.2->google-auth[aiohttp]>=2.5.0->gsutil) (2.0.4)\n",
      "Requirement already satisfied: cffi>=1.12 in /Users/dileep.gadiraju/opt/anaconda3/lib/python3.9/site-packages (from cryptography>=3.3->pyOpenSSL>=0.13->gsutil) (1.15.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/dileep.gadiraju/opt/anaconda3/lib/python3.9/site-packages (from requests<3.0.0dev,>=2.20.0->google-auth[aiohttp]>=2.5.0->gsutil) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/dileep.gadiraju/opt/anaconda3/lib/python3.9/site-packages (from requests<3.0.0dev,>=2.20.0->google-auth[aiohttp]>=2.5.0->gsutil) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/dileep.gadiraju/opt/anaconda3/lib/python3.9/site-packages (from requests<3.0.0dev,>=2.20.0->google-auth[aiohttp]>=2.5.0->gsutil) (1.26.13)\n",
      "Requirement already satisfied: pycparser in /Users/dileep.gadiraju/opt/anaconda3/lib/python3.9/site-packages (from cffi>=1.12->cryptography>=3.3->pyOpenSSL>=0.13->gsutil) (2.21)\n"
     ]
    }
   ],
   "source": [
    "# !pip install -r requirements.txt\n",
    "!pip install gsutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Kafka"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install Strimzi on cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"strimzi\" already exists with the same configuration, skipping\n"
     ]
    }
   ],
   "source": [
    "!helm repo add strimzi https://strimzi.io/charts/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "release \"my-release\" uninstalled\n",
      "Error: uninstall: Release name is invalid: strimzi/strimzi-kafka-operator\n",
      "NAME: my-release\n",
      "LAST DEPLOYED: Thu Dec 22 14:12:01 2022\n",
      "NAMESPACE: seldon\n",
      "STATUS: deployed\n",
      "REVISION: 1\n",
      "TEST SUITE: None\n",
      "NOTES:\n",
      "Thank you for installing strimzi-kafka-operator-0.32.0\n",
      "\n",
      "To create a Kafka cluster refer to the following documentation.\n",
      "\n",
      "https://strimzi.io/docs/operators/latest/deploying.html#deploying-cluster-operator-helm-chart-str\n"
     ]
    }
   ],
   "source": [
    "!helm uninstall my-release strimzi/strimzi-kafka-operator\n",
    "!helm install my-release strimzi/strimzi-kafka-operator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the following to whether you are running a local Kind cluster or a cloud based cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## strimzi operator image needed. \n",
    "## kind load docker-image quay.io/strimzi/operator:0.32.0  --name seldon\n",
    "clusterType = \"kind\"\n",
    "# clusterType=\"cloud\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error from server (AlreadyExists): namespaces \"seldon\" already exists\n",
      "Context \"kind-seldon\" modified.\n",
      "    namespace: seldon\n"
     ]
    }
   ],
   "source": [
    "#### Create Seldon ns and set as current context\n",
    "!kubectl create namespace seldon\n",
    "!kubectl config set-context $(kubectl config current-context) --namespace=seldon\n",
    "!kubectl config view | grep namespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting kafka-jbod.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile kafka-jbod.yaml\n",
    "apiVersion: kafka.strimzi.io/v1beta2\n",
    "kind: Kafka\n",
    "metadata:\n",
    "  name: my-cluster\n",
    "spec:\n",
    "  kafka:\n",
    "    version: 3.1.0\n",
    "    replicas: 1\n",
    "    listeners:\n",
    "      - name: plain\n",
    "        port: 9092\n",
    "        type: loadbalancer\n",
    "        tls: false\n",
    "      - name: tls\n",
    "        port: 9093\n",
    "        type: loadbalancer\n",
    "        tls: true\n",
    "    storage:\n",
    "      type: jbod\n",
    "      volumes:\n",
    "      - id: 0\n",
    "        type: persistent-claim\n",
    "        size: 100Gi\n",
    "        deleteClaim: false\n",
    "    config:\n",
    "      offsets.topic.replication.factor: 1\n",
    "      transaction.state.log.replication.factor: 1\n",
    "      transaction.state.log.min.isr: 1\n",
    "      auto.create.topics.enable: true\n",
    "      default.replication.factor: 1\n",
    "      min.insync.replicas: 1\n",
    "  zookeeper:\n",
    "    replicas: 1\n",
    "    storage:\n",
    "      type: persistent-claim\n",
    "      size: 100Gi\n",
    "      deleteClaim: false\n",
    "  entityOperator:\n",
    "    topicOperator: {}\n",
    "    userOperator: {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kafka.kafka.strimzi.io \"my-cluster\" deleted\n",
      "kafka.kafka.strimzi.io/my-cluster created\n"
     ]
    }
   ],
   "source": [
    "if clusterType == \"kind\":\n",
    "    !kubectl delete -f ./seldon-core/examples/kafka/cifar10/cluster-kind.yaml\n",
    "    !kubectl apply -f ./seldon-core/examples/kafka/cifar10/cluster-kind.yaml\n",
    "else:\n",
    "    # !kubectl delete -f ./seldon-core/examples/kafka/cifar10/cluster-cloud.yaml\n",
    "    !kubectl apply -f ./seldon-core/examples/kafka/cifar10/cluster-cloud.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME         DESIRED KAFKA REPLICAS   DESIRED ZK REPLICAS   READY   WARNINGS\n",
      "my-cluster   1                        1                             \n",
      "NAME                                              TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)             AGE\n",
      "model-server-triton-default                       ClusterIP   10.96.250.111   <none>        8000/TCP,5001/TCP   44h\n",
      "model-server-triton-default-model-server-triton   ClusterIP   10.96.209.237   <none>        9000/TCP,9500/TCP   44h\n"
     ]
    }
   ],
   "source": [
    "# get Kafka and check\n",
    "!kubectl get Kafka\n",
    "!kubectl get svc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get broker endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: BROKER=Error from server (NotFound): services \"my-cluster-kafka-plain-bootstrap\" not found:9092\n"
     ]
    }
   ],
   "source": [
    "if clusterType == \"kind\":\n",
    "    res = !kubectl get service my-cluster-kafka-plain-bootstrap -n seldon -o=jsonpath='{.status.loadBalancer.ingress[0].ip}'\n",
    "    ip = res[0]\n",
    "    %env BROKER=$ip:9092\n",
    "else:\n",
    "    res = !kubectl get service my-cluster-kafka-external-bootstrap -o=jsonpath='{.status.loadBalancer.ingress[0].hostname}'\n",
    "    if len(res) == 1:\n",
    "        hostname = res[0]\n",
    "        %env BROKER=$h:9094\n",
    "    else:\n",
    "        res = !kubectl get service my-cluster-kafka-external-bootstrap -o=jsonpath='{.status.loadBalancer.ingress[0].ip}'\n",
    "        ip = res[0]\n",
    "        %env BROKER=$ip:9094"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting topics.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile topics.yaml\n",
    "apiVersion: kafka.strimzi.io/v1beta1\n",
    "kind: KafkaTopic\n",
    "metadata:\n",
    "  name: cifar10-rest-input\n",
    "  labels:\n",
    "    strimzi.io/cluster: \"my-cluster\"\n",
    "spec:\n",
    "  partitions: 2\n",
    "  replicas: 1\n",
    "---\n",
    "apiVersion: kafka.strimzi.io/v1beta1\n",
    "kind: KafkaTopic\n",
    "metadata:\n",
    "  name: cifar10-rest-output\n",
    "  labels:\n",
    "    strimzi.io/cluster: \"my-cluster\"\n",
    "spec:\n",
    "  partitions: 2\n",
    "  replicas: 1\n",
    "---\n",
    "apiVersion: kafka.strimzi.io/v1beta1\n",
    "kind: KafkaTopic\n",
    "metadata:\n",
    "  name: cifar10-grpc-input\n",
    "  labels:\n",
    "    strimzi.io/cluster: \"my-cluster\"\n",
    "spec:\n",
    "  partitions: 2\n",
    "  replicas: 1\n",
    "---\n",
    "apiVersion: kafka.strimzi.io/v1beta1\n",
    "kind: KafkaTopic\n",
    "metadata:\n",
    "  name: cifar10-grpc-output\n",
    "  labels:\n",
    "    strimzi.io/cluster: \"my-cluster\"\n",
    "spec:\n",
    "  partitions: 2\n",
    "  replicas: 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kafkatopic.kafka.strimzi.io \"cifar10-rest-input\" deleted\n",
      "kafkatopic.kafka.strimzi.io \"cifar10-rest-output\" deleted\n",
      "kafkatopic.kafka.strimzi.io \"cifar10-grpc-input\" deleted\n",
      "kafkatopic.kafka.strimzi.io \"cifar10-grpc-output\" deleted\n",
      "kafkatopic.kafka.strimzi.io/cifar10-rest-input created\n",
      "kafkatopic.kafka.strimzi.io/cifar10-rest-output created\n",
      "kafkatopic.kafka.strimzi.io/cifar10-grpc-input created\n",
      "kafkatopic.kafka.strimzi.io/cifar10-grpc-output created\n"
     ]
    }
   ],
   "source": [
    "!kubectl delete -f topics.yaml\n",
    "!kubectl apply -f topics.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                  CLUSTER      PARTITIONS   REPLICATION FACTOR   READY\n",
      "cifar10-grpc-input    my-cluster   2            1                    \n",
      "cifar10-grpc-output   my-cluster   2            1                    \n",
      "cifar10-rest-input    my-cluster   2            1                    \n",
      "cifar10-rest-output   my-cluster   2            1                    \n"
     ]
    }
   ],
   "source": [
    "## Get Topics \n",
    "!kubectl get KafkaTopic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Seldon\n",
    "\n",
    "  * [Install seldon via ansible](https://github.com/SeldonIO/ansible-k8s-collection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Test Request Data\n",
    "We have two example datasets containing 50,000 requests in tensorflow serving format for CIFAR10. One in JSON format and one as length encoded proto buffers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://seldon-datasets/cifar10/requests/tensorflow/cifar10_tensorflow.json.gz...\n",
      "If you experience problems with multiprocessing on MacOS, they might be related to https://bugs.python.org/issue33725. You can disable multiprocessing by editing your .boto config or by adding the following flag to your command: `-o \"GSUtil:parallel_process_count=1\"`. Note that multithreading is still available even if you disable multiprocessing.\n",
      "\n",
      "| [1 files][324.3 MiB/324.3 MiB]    7.5 MiB/s                                   \n",
      "Operation completed over 1 objects/324.3 MiB.                                    \n",
      "cifar10_tensorflow.json already exists -- do you wish to overwrite (y or n)? ^C\n",
      "Copying gs://seldon-datasets/cifar10/requests/tensorflow/cifar10_tensorflow.proto...\n",
      "If you experience problems with multiprocessing on MacOS, they might be related to https://bugs.python.org/issue33725. You can disable multiprocessing by editing your .boto config or by adding the following flag to your command: `-o \"GSUtil:parallel_process_count=1\"`. Note that multithreading is still available even if you disable multiprocessing.\n",
      "\n",
      "^C[0 files][ 92.8 MiB/589.3 MiB]    7.1 MiB/s                                   \n",
      "Exception in UIThread: \n",
      "Caught CTRL-C (signal 2) - exiting\n"
     ]
    }
   ],
   "source": [
    "!gsutil cp gs://seldon-datasets/cifar10/requests/tensorflow/cifar10_tensorflow.json.gz cifar10_tensorflow.json.gz\n",
    "!gunzip cifar10_tensorflow.json.gz\n",
    "!gsutil cp gs://seldon-datasets/cifar10/requests/tensorflow/cifar10_tensorflow.proto cifar10_tensorflow.proto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test CIFAR10 REST Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload tensorflow serving rest requests to kafka. This may take some time dependent on your network connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-21 17:27:11.167444: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "%4|1671623835.971|CONFWARN|TI-MAC-088.local#producer-1| [thrd:app]: Configuration property group.id is a consumer property and will be ignored by this producer instance\n",
      "%4|1671623835.971|CONFWARN|TI-MAC-088.local#producer-1| [thrd:app]: Configuration property auto.offset.reset is a consumer property and will be ignored by this producer instance\n",
      "%3|1671623835.971|FAIL|TI-MAC-088.local#producer-1| [thrd:Error from server (NotFound): services \"my-cluster-kafka-plain-]: Error from server (NotFound): services \"my-cluster-kafka-plain-bootstrap\" not found:9092:9092/bootstrap: Failed to resolve 'Error from server (NotFound): services \"my-cluster-kafka-plain-bootstrap\" not found:9092:9092': nodename nor servname provided, or not known (after 0ms in state CONNECT)\n",
      "messages sent: 100\n",
      "%3|1671623837.973|FAIL|TI-MAC-088.local#producer-1| [thrd:Error from server (NotFound): services \"my-cluster-kafka-plain-]: Error from server (NotFound): services \"my-cluster-kafka-plain-bootstrap\" not found:9092:9092/bootstrap: Failed to resolve 'Error from server (NotFound): services \"my-cluster-kafka-plain-bootstrap\" not found:9092:9092': nodename nor servname provided, or not known (after 0ms in state CONNECT, 1 identical error(s) suppressed)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "# !pip install confluent_kafka\n",
    "# !pip install tensorflow-serving-api\n",
    "!python ./seldon-core/util/kafka/test-client.py produce $BROKER cifar10-rest-input --file cifar10_tensorflow.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: BROKER_CIP=Error from server (NotFound): services \"my-cluster-kafka-plain-bootstrap\" not found\n"
     ]
    }
   ],
   "source": [
    "res = !kubectl get service my-cluster-kafka-plain-bootstrap -o=jsonpath='{.spec.clusterIP}'\n",
    "ip = res[0]\n",
    "%env BROKER_CIP=$ip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting cifar10_rest.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile cifar10_rest.yaml\n",
    "apiVersion: machinelearning.seldon.io/v1\n",
    "kind: SeldonDeployment\n",
    "metadata:\n",
    "  name: tfserving-cifar10\n",
    "spec:\n",
    "  protocol: tensorflow\n",
    "  transport: rest\n",
    "  serverType: kafka  \n",
    "  predictors:\n",
    "  - componentSpecs:\n",
    "    - spec:\n",
    "        containers:\n",
    "        - args: \n",
    "          - --port=8500\n",
    "          - --rest_api_port=8501\n",
    "          - --model_name=resnet32\n",
    "          - --model_base_path=gs://seldon-models/tfserving/cifar10/resnet32\n",
    "          - --enable_batching\n",
    "          image: tensorflow/serving\n",
    "          name: resnet32\n",
    "          ports:\n",
    "          - containerPort: 8501\n",
    "            name: http\n",
    "    svcOrchSpec:\n",
    "      env:\n",
    "      - name: KAFKA_BROKER\n",
    "        value: BROKER_IP\n",
    "      - name: KAFKA_INPUT_TOPIC\n",
    "        value: cifar10-rest-input\n",
    "      - name: KAFKA_OUTPUT_TOPIC\n",
    "        value: cifar10-rest-output\n",
    "    graph:\n",
    "      name: resnet32\n",
    "      type: MODEL\n",
    "      endpoint:\n",
    "        service_port: 8501\n",
    "    name: model\n",
    "    replicas: 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error: error parsing STDIN: error converting YAML to JSON: yaml: line 27: mapping values are not allowed in this context\n"
     ]
    }
   ],
   "source": [
    "!cat cifar10_rest.yaml | sed s/BROKER_IP/$BROKER_CIP:9092/ | kubectl apply -f -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the metrics dashboard for Seldon you should see throughput we are getting. For a single replica on GKE with n1-standard-4 nodes we can see roughly 150 requests per second being processed.\n",
    "\n",
    "![rest](tensorflow-rest-kafka.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error from server (NotFound): error when deleting \"cifar10_rest.yaml\": seldondeployments.machinelearning.seldon.io \"tfserving-cifar10\" not found\n"
     ]
    }
   ],
   "source": [
    "!kubectl delete -f cifar10_rest.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test CIFAR10 gRPC Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload tensorflow serving rest requests to kafka. This is a file of protobuffer `tenserflow.serving.PredictRequest` ([defn](https://github.com/tensorflow/serving/blob/master/tensorflow_serving/apis/predict.proto)). Each binary protobuffer is prefixed by the numbre of bytes. Out test-client python script reads them and sends to our topic. This may take some time dependent on your network connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-19 15:23:40.161293: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-05-19 15:23:40.161322: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "%4|1652970223.000|CONFWARN|clive-T470p#producer-1| [thrd:app]: Configuration property group.id is a consumer property and will be ignored by this producer instance\n",
      "%4|1652970223.000|CONFWARN|clive-T470p#producer-1| [thrd:app]: Configuration property auto.offset.reset is a consumer property and will be ignored by this producer instance\n",
      "Messages sent: 100\n",
      "Messages sent: 200\n",
      "Messages sent: 300\n",
      "Messages sent: 400\n",
      "Messages sent: 500\n",
      "Messages sent: 600\n",
      "Messages sent: 700\n",
      "Messages sent: 800\n",
      "Messages sent: 900\n",
      "Messages sent: 1000\n",
      "Messages sent: 1100\n",
      "Messages sent: 1200\n",
      "Messages sent: 1300\n",
      "Messages sent: 1400\n",
      "Messages sent: 1500\n",
      "Messages sent: 1600\n",
      "Messages sent: 1700\n",
      "Messages sent: 1800\n",
      "Messages sent: 1900\n",
      "Messages sent: 2000\n",
      "Messages sent: 2100\n",
      "Messages sent: 2200\n",
      "Messages sent: 2300\n",
      "Messages sent: 2400\n",
      "Messages sent: 2500\n",
      "Messages sent: 2600\n",
      "Messages sent: 2700\n",
      "Messages sent: 2800\n",
      "Messages sent: 2900\n",
      "Messages sent: 3000\n",
      "Messages sent: 3100\n",
      "Messages sent: 3200\n",
      "Messages sent: 3300\n",
      "Messages sent: 3400\n",
      "Messages sent: 3500\n",
      "Messages sent: 3600\n",
      "Messages sent: 3700\n",
      "Messages sent: 3800\n",
      "Messages sent: 3900\n",
      "Messages sent: 4000\n",
      "Messages sent: 4100\n",
      "Messages sent: 4200\n",
      "Messages sent: 4300\n",
      "Messages sent: 4400\n",
      "Messages sent: 4500\n",
      "Messages sent: 4600\n",
      "Messages sent: 4700\n",
      "Messages sent: 4800\n",
      "Messages sent: 4900\n",
      "Messages sent: 5000\n",
      "Messages sent: 5100\n",
      "Messages sent: 5200\n",
      "Messages sent: 5300\n",
      "Messages sent: 5400\n",
      "Messages sent: 5500\n",
      "Messages sent: 5600\n",
      "Messages sent: 5700\n",
      "Messages sent: 5800\n",
      "Messages sent: 5900\n",
      "Messages sent: 6000\n",
      "Messages sent: 6100\n",
      "Messages sent: 6200\n",
      "Messages sent: 6300\n",
      "Messages sent: 6400\n",
      "Messages sent: 6500\n",
      "Messages sent: 6600\n",
      "Messages sent: 6700\n",
      "Messages sent: 6800\n",
      "Messages sent: 6900\n",
      "Messages sent: 7000\n",
      "Messages sent: 7100\n",
      "Messages sent: 7200\n",
      "Messages sent: 7300\n",
      "Messages sent: 7400\n",
      "Messages sent: 7500\n",
      "Messages sent: 7600\n",
      "Messages sent: 7700\n",
      "Messages sent: 7800\n",
      "Messages sent: 7900\n",
      "Messages sent: 8000\n",
      "Messages sent: 8100\n",
      "Messages sent: 8200\n",
      "Messages sent: 8300\n",
      "Messages sent: 8400\n",
      "Messages sent: 8500\n",
      "Messages sent: 8600\n",
      "Messages sent: 8700\n",
      "Messages sent: 8800\n",
      "Messages sent: 8900\n",
      "Messages sent: 9000\n",
      "Messages sent: 9100\n",
      "Messages sent: 9200\n",
      "Messages sent: 9300\n",
      "Messages sent: 9400\n",
      "Messages sent: 9500\n",
      "Messages sent: 9600\n",
      "Messages sent: 9700\n",
      "Messages sent: 9800\n",
      "Messages sent: 9900\n",
      "Messages sent: 10000\n",
      "Messages sent: 10100\n",
      "Messages sent: 10200\n",
      "Messages sent: 10300\n",
      "Messages sent: 10400\n",
      "Messages sent: 10500\n",
      "Messages sent: 10600\n",
      "Messages sent: 10700\n",
      "Messages sent: 10800\n",
      "Messages sent: 10900\n",
      "Messages sent: 11000\n",
      "Messages sent: 11100\n",
      "Messages sent: 11200\n",
      "Messages sent: 11300\n",
      "Messages sent: 11400\n",
      "Messages sent: 11500\n",
      "Messages sent: 11600\n",
      "Messages sent: 11700\n",
      "Messages sent: 11800\n",
      "Messages sent: 11900\n",
      "Messages sent: 12000\n",
      "Messages sent: 12100\n",
      "Messages sent: 12200\n",
      "Messages sent: 12300\n",
      "Messages sent: 12400\n",
      "Messages sent: 12500\n",
      "Messages sent: 12600\n",
      "Messages sent: 12700\n",
      "Messages sent: 12800\n",
      "Messages sent: 12900\n",
      "Messages sent: 13000\n",
      "Messages sent: 13100\n",
      "Messages sent: 13200\n",
      "Messages sent: 13300\n",
      "Messages sent: 13400\n",
      "Messages sent: 13500\n",
      "Messages sent: 13600\n",
      "Messages sent: 13700\n",
      "Messages sent: 13800\n",
      "Messages sent: 13900\n",
      "Messages sent: 14000\n",
      "Messages sent: 14100\n",
      "Messages sent: 14200\n",
      "Messages sent: 14300\n",
      "Messages sent: 14400\n",
      "Messages sent: 14500\n",
      "Messages sent: 14600\n",
      "Messages sent: 14700\n",
      "Messages sent: 14800\n",
      "Messages sent: 14900\n",
      "Messages sent: 15000\n",
      "Messages sent: 15100\n",
      "Messages sent: 15200\n",
      "Messages sent: 15300\n",
      "Messages sent: 15400\n",
      "Messages sent: 15500\n",
      "Messages sent: 15600\n",
      "Messages sent: 15700\n",
      "Messages sent: 15800\n",
      "Messages sent: 15900\n",
      "Messages sent: 16000\n",
      "Messages sent: 16100\n",
      "Messages sent: 16200\n",
      "Messages sent: 16300\n",
      "Messages sent: 16400\n",
      "Messages sent: 16500\n",
      "Messages sent: 16600\n",
      "Messages sent: 16700\n",
      "Messages sent: 16800\n",
      "Messages sent: 16900\n",
      "Messages sent: 17000\n",
      "Messages sent: 17100\n",
      "Messages sent: 17200\n",
      "Messages sent: 17300\n",
      "Messages sent: 17400\n",
      "Messages sent: 17500\n",
      "Messages sent: 17600\n",
      "Messages sent: 17700\n",
      "Messages sent: 17800\n",
      "Messages sent: 17900\n",
      "Messages sent: 18000\n",
      "Messages sent: 18100\n",
      "Messages sent: 18200\n",
      "Messages sent: 18300\n",
      "Messages sent: 18400\n",
      "Messages sent: 18500\n",
      "Messages sent: 18600\n",
      "Messages sent: 18700\n",
      "Messages sent: 18800\n",
      "Messages sent: 18900\n",
      "Messages sent: 19000\n",
      "Messages sent: 19100\n",
      "Messages sent: 19200\n",
      "Messages sent: 19300\n",
      "Messages sent: 19400\n",
      "Messages sent: 19500\n",
      "Messages sent: 19600\n",
      "Messages sent: 19700\n",
      "Messages sent: 19800\n",
      "Messages sent: 19900\n",
      "Messages sent: 20000\n",
      "Messages sent: 20100\n",
      "Messages sent: 20200\n",
      "Messages sent: 20300\n",
      "Messages sent: 20400\n",
      "Messages sent: 20500\n",
      "Messages sent: 20600\n",
      "Messages sent: 20700\n",
      "Messages sent: 20800\n",
      "Messages sent: 20900\n",
      "Messages sent: 21000\n",
      "Messages sent: 21100\n",
      "Messages sent: 21200\n",
      "Messages sent: 21300\n",
      "Messages sent: 21400\n",
      "Messages sent: 21500\n",
      "Messages sent: 21600\n",
      "Messages sent: 21700\n",
      "Messages sent: 21800\n",
      "Messages sent: 21900\n",
      "Messages sent: 22000\n",
      "Messages sent: 22100\n",
      "Messages sent: 22200\n",
      "Messages sent: 22300\n",
      "Messages sent: 22400\n",
      "Messages sent: 22500\n",
      "Messages sent: 22600\n",
      "Messages sent: 22700\n",
      "Messages sent: 22800\n",
      "Messages sent: 22900\n",
      "Messages sent: 23000\n",
      "Messages sent: 23100\n",
      "Messages sent: 23200\n",
      "Messages sent: 23300\n",
      "Messages sent: 23400\n",
      "Messages sent: 23500\n",
      "Messages sent: 23600\n",
      "Messages sent: 23700\n",
      "Messages sent: 23800\n",
      "Messages sent: 23900\n",
      "Messages sent: 24000\n",
      "Messages sent: 24100\n",
      "Messages sent: 24200\n",
      "Messages sent: 24300\n",
      "Messages sent: 24400\n",
      "Messages sent: 24500\n",
      "Messages sent: 24600\n",
      "Messages sent: 24700\n",
      "Messages sent: 24800\n",
      "Messages sent: 24900\n",
      "Messages sent: 25000\n",
      "Messages sent: 25100\n",
      "Messages sent: 25200\n",
      "Messages sent: 25300\n",
      "Messages sent: 25400\n",
      "Messages sent: 25500\n",
      "Messages sent: 25600\n",
      "Messages sent: 25700\n",
      "Messages sent: 25800\n",
      "Messages sent: 25900\n",
      "Messages sent: 26000\n",
      "Messages sent: 26100\n",
      "Messages sent: 26200\n",
      "Messages sent: 26300\n",
      "Messages sent: 26400\n",
      "Messages sent: 26500\n",
      "Messages sent: 26600\n",
      "Messages sent: 26700\n",
      "Messages sent: 26800\n",
      "Messages sent: 26900\n",
      "Messages sent: 27000\n",
      "Messages sent: 27100\n",
      "Messages sent: 27200\n",
      "Messages sent: 27300\n",
      "Messages sent: 27400\n",
      "Messages sent: 27500\n",
      "Messages sent: 27600\n",
      "Messages sent: 27700\n",
      "Messages sent: 27800\n",
      "Messages sent: 27900\n",
      "Messages sent: 28000\n",
      "Messages sent: 28100\n",
      "Messages sent: 28200\n",
      "Messages sent: 28300\n",
      "Messages sent: 28400\n",
      "Messages sent: 28500\n",
      "Messages sent: 28600\n",
      "Messages sent: 28700\n",
      "Messages sent: 28800\n",
      "Messages sent: 28900\n",
      "Messages sent: 29000\n",
      "Messages sent: 29100\n",
      "Messages sent: 29200\n",
      "Messages sent: 29300\n",
      "Messages sent: 29400\n",
      "Messages sent: 29500\n",
      "Messages sent: 29600\n",
      "Messages sent: 29700\n",
      "Messages sent: 29800\n",
      "Messages sent: 29900\n",
      "Messages sent: 30000\n",
      "Messages sent: 30100\n",
      "Messages sent: 30200\n",
      "Messages sent: 30300\n",
      "Messages sent: 30400\n",
      "Messages sent: 30500\n",
      "Messages sent: 30600\n",
      "Messages sent: 30700\n",
      "Messages sent: 30800\n",
      "Messages sent: 30900\n",
      "Messages sent: 31000\n",
      "Messages sent: 31100\n",
      "Messages sent: 31200\n",
      "Messages sent: 31300\n",
      "Messages sent: 31400\n",
      "Messages sent: 31500\n",
      "Messages sent: 31600\n",
      "Messages sent: 31700\n",
      "Messages sent: 31800\n",
      "Messages sent: 31900\n",
      "Messages sent: 32000\n",
      "Messages sent: 32100\n",
      "Messages sent: 32200\n",
      "Messages sent: 32300\n",
      "Messages sent: 32400\n",
      "Messages sent: 32500\n",
      "Messages sent: 32600\n",
      "Messages sent: 32700\n",
      "Messages sent: 32800\n",
      "Messages sent: 32900\n",
      "Messages sent: 33000\n",
      "Messages sent: 33100\n",
      "Messages sent: 33200\n",
      "Messages sent: 33300\n",
      "Messages sent: 33400\n",
      "Messages sent: 33500\n",
      "Messages sent: 33600\n",
      "Messages sent: 33700\n",
      "Messages sent: 33800\n",
      "Messages sent: 33900\n",
      "Messages sent: 34000\n",
      "Messages sent: 34100\n",
      "Messages sent: 34200\n",
      "Messages sent: 34300\n",
      "Messages sent: 34400\n",
      "Messages sent: 34500\n",
      "Messages sent: 34600\n",
      "Messages sent: 34700\n",
      "Messages sent: 34800\n",
      "Messages sent: 34900\n",
      "Messages sent: 35000\n",
      "Messages sent: 35100\n",
      "Messages sent: 35200\n",
      "Messages sent: 35300\n",
      "Messages sent: 35400\n",
      "Messages sent: 35500\n",
      "Messages sent: 35600\n",
      "Messages sent: 35700\n",
      "Messages sent: 35800\n",
      "Messages sent: 35900\n",
      "Messages sent: 36000\n",
      "Messages sent: 36100\n",
      "Messages sent: 36200\n",
      "Messages sent: 36300\n",
      "Messages sent: 36400\n",
      "Messages sent: 36500\n",
      "Messages sent: 36600\n",
      "Messages sent: 36700\n",
      "Messages sent: 36800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Messages sent: 36900\n",
      "Messages sent: 37000\n",
      "Messages sent: 37100\n",
      "Messages sent: 37200\n",
      "Messages sent: 37300\n",
      "Messages sent: 37400\n",
      "Messages sent: 37500\n",
      "Messages sent: 37600\n",
      "Messages sent: 37700\n",
      "Messages sent: 37800\n",
      "Messages sent: 37900\n",
      "Messages sent: 38000\n",
      "Messages sent: 38100\n",
      "Messages sent: 38200\n",
      "Messages sent: 38300\n",
      "Messages sent: 38400\n",
      "Messages sent: 38500\n",
      "Messages sent: 38600\n",
      "Messages sent: 38700\n",
      "Messages sent: 38800\n",
      "Messages sent: 38900\n",
      "Messages sent: 39000\n",
      "Messages sent: 39100\n",
      "Messages sent: 39200\n",
      "Messages sent: 39300\n",
      "Messages sent: 39400\n",
      "Messages sent: 39500\n",
      "Messages sent: 39600\n",
      "Messages sent: 39700\n",
      "Messages sent: 39800\n",
      "Messages sent: 39900\n",
      "Messages sent: 40000\n",
      "Messages sent: 40100\n",
      "Messages sent: 40200\n",
      "Messages sent: 40300\n",
      "Messages sent: 40400\n",
      "Messages sent: 40500\n",
      "Messages sent: 40600\n",
      "Messages sent: 40700\n",
      "Messages sent: 40800\n",
      "Messages sent: 40900\n",
      "Messages sent: 41000\n",
      "Messages sent: 41100\n",
      "Messages sent: 41200\n",
      "Messages sent: 41300\n",
      "Messages sent: 41400\n",
      "Messages sent: 41500\n",
      "Messages sent: 41600\n",
      "Messages sent: 41700\n",
      "Messages sent: 41800\n",
      "Messages sent: 41900\n",
      "Messages sent: 42000\n",
      "Messages sent: 42100\n",
      "Messages sent: 42200\n",
      "Messages sent: 42300\n",
      "Messages sent: 42400\n",
      "Messages sent: 42500\n",
      "Messages sent: 42600\n",
      "Messages sent: 42700\n",
      "Messages sent: 42800\n",
      "Messages sent: 42900\n",
      "Messages sent: 43000\n",
      "Messages sent: 43100\n",
      "Messages sent: 43200\n",
      "Messages sent: 43300\n",
      "Messages sent: 43400\n",
      "Messages sent: 43500\n",
      "Messages sent: 43600\n",
      "Messages sent: 43700\n",
      "Messages sent: 43800\n",
      "Messages sent: 43900\n",
      "Messages sent: 44000\n",
      "Messages sent: 44100\n",
      "Messages sent: 44200\n",
      "Messages sent: 44300\n",
      "Messages sent: 44400\n",
      "Messages sent: 44500\n",
      "Messages sent: 44600\n",
      "Messages sent: 44700\n",
      "Messages sent: 44800\n",
      "Messages sent: 44900\n",
      "Messages sent: 45000\n",
      "Messages sent: 45100\n",
      "Messages sent: 45200\n",
      "Messages sent: 45300\n",
      "Messages sent: 45400\n",
      "Messages sent: 45500\n",
      "Messages sent: 45600\n",
      "Messages sent: 45700\n",
      "Messages sent: 45800\n",
      "Messages sent: 45900\n",
      "Messages sent: 46000\n",
      "Messages sent: 46100\n",
      "Messages sent: 46200\n",
      "Messages sent: 46300\n",
      "Messages sent: 46400\n",
      "Messages sent: 46500\n",
      "Messages sent: 46600\n",
      "Messages sent: 46700\n",
      "Messages sent: 46800\n",
      "Messages sent: 46900\n",
      "Messages sent: 47000\n",
      "Messages sent: 47100\n",
      "Messages sent: 47200\n",
      "Messages sent: 47300\n",
      "Messages sent: 47400\n",
      "Messages sent: 47500\n",
      "Messages sent: 47600\n",
      "Messages sent: 47700\n",
      "Messages sent: 47800\n",
      "Messages sent: 47900\n",
      "Messages sent: 48000\n",
      "Messages sent: 48100\n",
      "Messages sent: 48200\n",
      "Messages sent: 48300\n",
      "Messages sent: 48400\n",
      "Messages sent: 48500\n",
      "Messages sent: 48600\n",
      "Messages sent: 48700\n",
      "Messages sent: 48800\n",
      "Messages sent: 48900\n",
      "Messages sent: 49000\n",
      "Messages sent: 49100\n",
      "Messages sent: 49200\n",
      "Messages sent: 49300\n",
      "Messages sent: 49400\n",
      "Messages sent: 49500\n",
      "Messages sent: 49600\n",
      "Messages sent: 49700\n",
      "Messages sent: 49800\n",
      "Messages sent: 49900\n",
      "Messages sent: 50000\n",
      "Final messages sent count: 50000\n"
     ]
    }
   ],
   "source": [
    "!python ./seldon-core/util/kafka/test-client.py produce $BROKER cifar10-grpc-input --file cifar10_tensorflow.proto --proto_name tensorflow.serving.PredictRequest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: BROKER_CIP=10.96.66.27\n"
     ]
    }
   ],
   "source": [
    "res = !kubectl get service my-cluster-kafka-plain-bootstrap -o=jsonpath='{.spec.clusterIP}'\n",
    "ip = res[0]\n",
    "%env BROKER_CIP=$ip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting cifar10_grpc.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile cifar10_grpc.yaml\n",
    "apiVersion: machinelearning.seldon.io/v1\n",
    "kind: SeldonDeployment\n",
    "metadata:\n",
    "  name: tfserving-cifar10\n",
    "spec:\n",
    "  protocol: tensorflow\n",
    "  transport: grpc\n",
    "  serverType: kafka  \n",
    "  predictors:\n",
    "  - componentSpecs:\n",
    "    - spec:\n",
    "        containers:\n",
    "        - args: \n",
    "          - --port=8500\n",
    "          - --rest_api_port=8501\n",
    "          - --model_name=resnet32\n",
    "          - --model_base_path=gs://seldon-models/tfserving/cifar10/resnet32\n",
    "          - --enable_batching          \n",
    "          image: tensorflow/serving\n",
    "          name: resnet32\n",
    "          ports:\n",
    "          - containerPort: 8500\n",
    "            name: grpc\n",
    "          - containerPort: 8501\n",
    "            name: http\n",
    "    svcOrchSpec:\n",
    "      env:\n",
    "      - name: KAFKA_BROKER\n",
    "        value: BROKER_IP\n",
    "      - name: KAFKA_INPUT_TOPIC\n",
    "        value: cifar10-grpc-input\n",
    "      - name: KAFKA_OUTPUT_TOPIC\n",
    "        value: cifar10-grpc-output\n",
    "    graph:\n",
    "      name: resnet32\n",
    "      type: MODEL\n",
    "      endpoint:\n",
    "        grpcPort: 8500\n",
    "        httpPort: 8501\n",
    "    name: model\n",
    "    replicas: 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seldondeployment.machinelearning.seldon.io/tfserving-cifar10 created\r\n"
     ]
    }
   ],
   "source": [
    "!cat cifar10_grpc.yaml | sed s/BROKER_IP/$BROKER_CIP:9092/ | kubectl apply -f -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the metrics dashboard for Seldon you should see throughput we are getting. For a single replica on GKE with n1-standard-4 nodes we can see around 220 requests per second being processed.\n",
    "\n",
    "![grpc](tensorflow-grpc-kafka.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seldondeployment.machinelearning.seldon.io \"tfserving-cifar10\" deleted\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl delete -f cifar10_grpc.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8 (default, Jun 17 2022, 15:24:29) \n[Clang 13.1.6 (clang-1316.0.21.2.5)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "0207f39545ce9b6005991c9fcae14dd869925620f8111abadc3e533d4fd7bd18"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
